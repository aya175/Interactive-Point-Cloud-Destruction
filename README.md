# 🖐️ Interactive Point Cloud Destruction with TouchDesigner

This project demonstrates an interactive system where users can manipulate and "destroy" a 3D point cloud using hand gestures detected via webcam. Built with **TouchDesigner** and **MediaPipe**, it showcases real-time interaction between computer vision and generative visuals.


## 🧰 Features

- **Real-Time Hand Tracking**: Utilizes MediaPipe to detect and track hand movements through the webcam.
- **Point Cloud Interaction**: Hand positions influence the behavior of the point cloud, allowing for dynamic manipulation and "destruction" effects.
- **Generative Visuals**: Creates engaging visual effects that respond to user interactions in real-time.
- **Customizable Parameters**: Adjust sensitivity, effect intensity, and other parameters to tailor the experience.

## 🛠️ Technologies Used

- [TouchDesigner](https://derivative.ca/) – Visual development platform for real-time interactive multimedia content.
- [MediaPipe](https://mediapipe.dev/) – Framework for building multimodal applied machine learning pipelines, used here for hand tracking.
- **Python** – Scripting within TouchDesigner to handle logic and data processing.

## 📁 Project Structure

# 🖐️ Interactive Point Cloud Destruction with TouchDesigner

This project demonstrates an interactive system where users can manipulate and "destroy" a 3D point cloud using hand gestures detected via webcam. Built with **TouchDesigner** and **MediaPipe**, it showcases real-time interaction between computer vision and generative visuals.

## 🧰 Features

- **Real-Time Hand Tracking**: Utilizes MediaPipe to detect and track hand movements through the webcam.
- **Point Cloud Interaction**: Hand positions influence the behavior of the point cloud, allowing for dynamic manipulation and "destruction" effects.
- **Generative Visuals**: Creates engaging visual effects that respond to user interactions in real-time.
- **Customizable Parameters**: Adjust sensitivity, effect intensity, and other parameters to tailor the experience.

## 🛠️ Technologies Used

- [TouchDesigner](https://derivative.ca/) – Visual development platform for real-time interactive multimedia content.
- [MediaPipe](https://mediapipe.dev/) – Framework for building multimodal applied machine learning pipelines, used here for hand tracking.
- **Python** – Scripting within TouchDesigner to handle logic and data processing.

## 📁 Project Structure


## 🚀 Getting Started

1. **Install Dependencies**:
   - Ensure you have the latest version of TouchDesigner installed.
   - Set up MediaPipe for hand tracking functionality.

2. **Run the Project**:
   - Open `pointcloud_interaction.toe` in TouchDesigner.
   - Allow access to your webcam when prompted.
   - Move your hand in front of the camera to interact with the point cloud.

3. **Customize**:
   - Explore the parameters within the project to adjust the visual effects and interaction sensitivity.

## 🔧 Customization Tips

- **Effect Intensity**: Modify the parameters controlling the force applied to the point cloud for more dramatic effects.
- **Visual Style**: Change the color schemes, point sizes, or add additional visual elements to enhance the aesthetic.
- **Interaction Zones**: Define specific areas within the frame where interactions have different effects.

## 📄 License

This project is open-source and available under the [MIT License](LICENSE).


---

Feel free to fork this repository and experiment with your own interactive visual effects!
